{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/08/17 17:29:17 WARN Utils: Your hostname, Bobert resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/08/17 17:29:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/17 17:29:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DataCleaning\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min,max\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyspark.sql.functions import col, when, unix_timestamp\n",
    "import math\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import IntegerType, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data for the Yellow Taxi dataset\n",
    "\n",
    "# check passenger_count, trip_distance, PU/DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount\n",
    "#, improvement_surcharge, songestion_surcharge\n",
    "\n",
    "ytaxi = spark.read.parquet('../data/curated/YellowTaxi_Checkpt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES FOR SELF\n",
    "\n",
    "# Yellow Taxi\n",
    "''' max trip distance is way too long, new york has 320sq miles of land, remove some entries\n",
    "\n",
    "    9 passenger rides are not legal and would not fit in a cab, the max allowed is 7 on cases where there is a child\n",
    "\n",
    "    min and max fare amounts are ridiculous, adjust them\n",
    "\n",
    "    extra min max are insane\n",
    "\n",
    "    negative mta_tax, also max is 42, maybe that's okay?\n",
    "\n",
    "    negative tip amount not possible, max is 4000 which is not right\n",
    "\n",
    "    negative tolls, max tolls\n",
    "\n",
    "    pos and neg improvement and congestion charges, these are probably meant to all be pos\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Analysis for Yellow Taxi dataset\n",
    "\n",
    "check_columns = ['passenger_count', 'trip_distance', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount'\n",
    ", 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "for column in check_columns:\n",
    "    ytaxi.agg(min(column),max(column)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "\n",
    "ytaxi_clean = ytaxi\n",
    "ytaxi_clean.where(F.col('trip_distance')>300)\n",
    "\n",
    "ytaxi.describe('trip_distance')\n",
    "#ytaxi.stat.approxQuantile('trip_distance', [0.9999],0.00001)\n",
    "#ytaxi.where(F.col('trip_distance')>55).count()\n",
    "#ytaxi.where(F.col('trip_distance')<0).count()\n",
    "\n",
    "ytaxi_clean = ytaxi.where((F.col('trip_distance')<55)&(F.col('trip_distance')>0.65)&(F.col('passenger_count')<=7)&\n",
    "                          (F.col('passenger_count')>=0)&(F.col('fare_amount')>2.5)&(F.col('tip_amount')>=0)\n",
    "                          &(F.col('tip_amount')<65)&(F.col('payment_type')!=2)&(F.col('RatecodeID')<=6)\n",
    "                          &(F.col('fare_amount')<250))\n",
    "\n",
    "\n",
    "(ytaxi_clean.count()*100)/ytaxi.count() # keeping 67.89% of original data as rest is corrupted\n",
    "\n",
    "#ytaxi_clean.approxQuantile('tip_amount',[0.9999],0.00001) ---65\n",
    "#ytaxi_clean.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytaxi_clean.describe('extra') # website says it should only include values of 0.5 and 1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column to check how long the trips were\n",
    "ytaxi_clean = ytaxi_clean.withColumn(\n",
    "    \"trip_duration\", \n",
    "    (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60\n",
    ")\n",
    "\n",
    "#ytaxi_clean.where(F.col('diff_minutes')==0).count()\n",
    "#ytaxi_clean.describe('diff_minutes')\n",
    "#ytaxi_clean.approxQuantile('diff_minutes',[0.0001,0.9999],0.00001) # 0.02, 1435\n",
    "\n",
    "ytaxi_clean.where(F.col('trip_duration')<=0.2).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average speed in new york is 4.5 mph\n",
    "\n",
    "ytaxi_clean = ytaxi_clean.withColumn(\n",
    "    'average_speed',\n",
    "    (col('trip_distance')/(col('trip_duration')/60))\n",
    ")\n",
    "\n",
    "# ytaxi_clean.approxQuantile('average_speed',[0.25,0.5,0.75],0.00001) #50, some more leadway is 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytaxi_clean = ytaxi_clean.where((col('average_speed')>4.4)&(col('average_speed')<65))\n",
    "\n",
    "ytaxi_clean = ytaxi_clean.where(col('trip_duration')>1)\n",
    "\n",
    "(ytaxi_clean.count()*100)/ytaxi.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that are irrelevant for the analysis\n",
    "ytaxi_clean = ytaxi_clean.drop('store_and_fwd_flag', 'extra', 'VendorID', 'mta_tax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all the entries are within the intended date range\n",
    "ytaxi_clean = ytaxi_clean.where((F.col('tpep_pickup_datetime')>='2023-12-01 00:00:00')&(F.col('tpep_pickup_datetime')<='2024-05-31 23:59:59')\n",
    "                          &(F.col('tpep_dropoff_datetime')>='2023-12-01 00:00:00')&(F.col('tpep_dropoff_datetime')<='2024-05-31 23:59:59'))\n",
    "\n",
    "# Adding in some more useful columns \n",
    "\n",
    "ytaxi_clean = ytaxi_clean.withColumn('pickup_day', F.date_format('tpep_pickup_datetime', 'E'))\n",
    "\n",
    "ytaxi_clean = ytaxi_clean.withColumn('pickup_hour', F.date_format('tpep_pickup_datetime', 'H'))\n",
    "ytaxi_clean = ytaxi_clean.withColumn('pickup_hour', ytaxi_clean['pickup_hour'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytaxi_clean.write.mode('overwrite').parquet('../data/curated/YellowTaxi_Cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the weather dataset\n",
    "\n",
    "weather = pd.read_csv('../data/landing/new york 2023-12-01 to 2024-05-31.csv')\n",
    "\n",
    "# dropping columns that are not realistic to check/impact days of everyday citizens or are irrelevant such as \n",
    "# stations, source, name, moonphase, \n",
    "weather.drop(['stations', 'name','solarradiation','solarenergy','precipprob','preciptype'],axis=1,inplace=True)\n",
    "\n",
    "weather.describe()\n",
    "# no further cleaning required, dataset seems clean\n",
    "\n",
    "weather.to_csv('../data/curated/Weather/WeatherClean.csv',index=False)\n",
    "\n",
    "weather.to_parquet('../data/curated/Weather/WeatherCleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytaxi_clean.count()*100/ytaxi.count() # 64.98% of the original data is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Combining the weather and ytaxi_clean datasets\n",
    "\n",
    "weather = spark.read.parquet('../data/curated/Weather/WeatherCleaned')\n",
    "ytaxi_clean = spark.read.parquet('../data/curated/YellowTaxi_Cleaned')\n",
    "# Converting datatype of datetime in weather to datetime type instead of string\n",
    "\n",
    "weather = weather.withColumn('datetime', F.regexp_replace('datetime', 'T', ' '))\n",
    "weather = weather.withColumn('datetime', F.to_timestamp('datetime', 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "from pyspark.sql.functions import date_trunc\n",
    "\n",
    "ytaxi_clean = ytaxi_clean.withColumn('tpep_pickup_datetime', date_trunc('hour', 'tpep_pickup_datetime'))\n",
    "ytaxi_clean = ytaxi_clean.withColumn('tpep_dropoff_datetime', date_trunc('hour', 'tpep_dropoff_datetime'))\n",
    "\n",
    "joined_df = ytaxi_clean.join(weather, ytaxi_clean.tpep_pickup_datetime == weather.datetime, \"left\")\n",
    "\n",
    "joined_df.write.parquet('../data/curated/YellowTaxi_Weather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
